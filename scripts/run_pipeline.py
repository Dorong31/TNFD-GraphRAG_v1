"""
ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

PDF ë¬¸ì„œë¥¼ ì½ì–´ Knowledge Graphë¥¼ êµ¬ì¶•í•˜ê³ 
ì§ˆì˜ì‘ë‹µì„ ìˆ˜í–‰í•˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python scripts/run_pipeline.py --pdf data/pdfs/sample.pdf
    python scripts/run_pipeline.py --query "ì´ ê¸°ì—…ì˜ ì£¼ìš” ë¦¬ìŠ¤í¬ëŠ”?"
"""

import argparse
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.config import validate_config
from src.data_pipeline.pdf_loader import load_pdf, get_pdf_info
from src.data_pipeline.chunker import create_chunks_from_pages
from src.extraction.extractor import TripleExtractor
from src.graph.neo4j_client import Neo4jClient
from src.graph.vector_store import VectorStore
from src.retrieval.generator import query_with_sources


def run_ingestion_pipeline(pdf_path: str, verbose: bool = True):
    """
    PDF ë¬¸ì„œë¥¼ Knowledge Graphë¡œ ë³€í™˜í•˜ëŠ” íŒŒì´í”„ë¼ì¸
    
    1. PDF ë¡œë“œ
    2. í…ìŠ¤íŠ¸ ì²­í‚¹
    3. Triple ì¶”ì¶œ
    4. Neo4j ì €ì¥
    5. ì„ë² ë”© ìƒì„± ë° ì €ì¥
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€
    """
    if verbose:
        print("=" * 60)
        print("TNFD-GraphRAG Ingestion Pipeline")
        print("=" * 60)
    
    # ì„¤ì • ê²€ì¦
    config_status = validate_config()
    if not config_status["google_api_key"]:
        print("âŒ Google API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    if not config_status["neo4j_password"]:
        print("âŒ Neo4j ë¹„ë°€ë²ˆí˜¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    # 1. PDF ë¡œë“œ
    if verbose:
        print(f"\nğŸ“„ Step 1: PDF ë¡œë“œ ì¤‘... ({pdf_path})")
    
    try:
        info = get_pdf_info(pdf_path)
        if verbose:
            print(f"   - íŒŒì¼ëª…: {info['filename']}")
            print(f"   - í˜ì´ì§€ ìˆ˜: {info['page_count']}")
        
        pages = load_pdf(pdf_path)
        if verbose:
            print(f"   âœ“ {len(pages)} í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ PDF ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    
    # 2. í…ìŠ¤íŠ¸ ì²­í‚¹
    if verbose:
        print("\nğŸ“ Step 2: í…ìŠ¤íŠ¸ ì²­í‚¹ ì¤‘...")
    
    chunks = create_chunks_from_pages(pages, chunk_method="size")
    if verbose:
        print(f"   âœ“ {len(chunks)} ì²­í¬ ìƒì„± ì™„ë£Œ")
    
    # 3. Triple ì¶”ì¶œ
    if verbose:
        print("\nğŸ” Step 3: Triple ì¶”ì¶œ ì¤‘...")
        print(f"   (ì´ ë‹¨ê³„ëŠ” LLM APIë¥¼ í˜¸ì¶œí•˜ë¯€ë¡œ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    
    try:
        extractor = TripleExtractor()
        
        def progress_callback(current, total):
            if verbose:
                print(f"\r   ì§„í–‰: {current}/{total} ({100*current/total:.1f}%)", end="")
        
        extraction_results = extractor.extract_batch(chunks, progress_callback)
        
        if verbose:
            print()  # ì¤„ë°”ê¿ˆ
            total_nodes = sum(len(r.nodes) for r in extraction_results)
            total_rels = sum(len(r.relationships) for r in extraction_results)
            print(f"   âœ“ {total_nodes} ë…¸ë“œ, {total_rels} ê´€ê³„ ì¶”ì¶œ ì™„ë£Œ")
    except Exception as e:
        print(f"\nâŒ Triple ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return False
    
    # 4. Neo4j ì €ì¥
    if verbose:
        print("\nğŸ’¾ Step 4: Neo4jì— ì €ì¥ ì¤‘...")
    
    try:
        neo4j_client = Neo4jClient()
        
        nodes_created = 0
        rels_created = 0
        
        for result in extraction_results:
            stats = neo4j_client.save_extraction_result(result)
            nodes_created += stats["nodes_created"]
            rels_created += stats["relationships_created"]
        
        if verbose:
            print(f"   âœ“ {nodes_created} ë…¸ë“œ, {rels_created} ê´€ê³„ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ Neo4j ì €ì¥ ì‹¤íŒ¨: {e}")
        return False
    
    # 5. ì„ë² ë”© ìƒì„± ë° ì €ì¥
    if verbose:
        print("\nğŸ§  Step 5: ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì¤‘...")
    
    try:
        vector_store = VectorStore(neo4j_client=neo4j_client)
        vector_store.create_vector_index()
        
        # Evidence ë…¸ë“œì˜ í…ìŠ¤íŠ¸ì™€ ID ìˆ˜ì§‘
        texts_and_ids = []
        for result in extraction_results:
            for node in result.nodes:
                if hasattr(node, 'text') and hasattr(node, 'id'):
                    texts_and_ids.append((node.text, node.id))
        
        if texts_and_ids:
            stored = vector_store.embed_batch(texts_and_ids)
            if verbose:
                print(f"   âœ“ {stored}/{len(texts_and_ids)} ì„ë² ë”© ì €ì¥ ì™„ë£Œ")
        
        vector_store.close()
    except Exception as e:
        print(f"âš ï¸ ì„ë² ë”© ì €ì¥ ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {e}")
    
    # ì™„ë£Œ
    if verbose:
        print("\n" + "=" * 60)
        print("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("=" * 60)
        
        # ìµœì¢… í†µê³„
        stats = neo4j_client.get_statistics()
        print(f"\nğŸ“Š ê·¸ë˜í”„ í†µê³„:")
        print(f"   - ì´ ë…¸ë“œ ìˆ˜: {stats['total_nodes']}")
        print(f"   - ì´ ê´€ê³„ ìˆ˜: {stats['total_relationships']}")
        if stats['nodes_by_type']:
            print("   - ë…¸ë“œ íƒ€ì…ë³„:")
            for t, c in stats['nodes_by_type'].items():
                print(f"       {t}: {c}")
        
        neo4j_client.close()
    
    return True


def run_query(question: str, verbose: bool = True):
    """
    ì§ˆì˜ì‘ë‹µ ìˆ˜í–‰
    
    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
    """
    if verbose:
        print("=" * 60)
        print("TNFD-GraphRAG Query")
        print("=" * 60)
        print(f"\nğŸ“Œ ì§ˆë¬¸: {question}\n")
    
    try:
        result = query_with_sources(question)
        
        print("ğŸ“ ë‹µë³€:")
        print("-" * 40)
        print(result["answer"])
        print("-" * 40)
        
        if result["sources"]:
            print("\nğŸ“š ì¶œì²˜:")
            for src in result["sources"]:
                print(f"   - {src['document']}, p.{src['page']} (ìœ ì‚¬ë„: {src['relevance_score']:.4f})")
        
        return True
    except Exception as e:
        print(f"âŒ ì§ˆì˜ ì‹¤íŒ¨: {e}")
        return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="TNFD-GraphRAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # PDF ë¬¸ì„œë¡œ Knowledge Graph êµ¬ì¶•
  python run_pipeline.py --pdf data/pdfs/sustainability_report.pdf
  
  # ì§ˆì˜ì‘ë‹µ ìˆ˜í–‰
  python run_pipeline.py --query "ì´ ê¸°ì—…ì˜ ì£¼ìš” ë¬¼ë¦¬ì  ë¦¬ìŠ¤í¬ëŠ”?"
  
  # PDF ì²˜ë¦¬ í›„ ë°”ë¡œ ì§ˆì˜
  python run_pipeline.py --pdf report.pdf --query "ìˆ˜ìì› ê´€ë¦¬ í˜„í™©ì€?"
        """
    )
    
    parser.add_argument(
        "--pdf",
        type=str,
        help="ì²˜ë¦¬í•  PDF íŒŒì¼ ê²½ë¡œ"
    )
    parser.add_argument(
        "--query", "-q",
        type=str,
        help="ì§ˆì˜í•  ì§ˆë¬¸"
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="ì§„í–‰ ìƒí™© ì¶œë ¥ ìµœì†Œí™”"
    )
    
    args = parser.parse_args()
    
    # ì•„ë¬´ ì¸ìë„ ì—†ìœ¼ë©´ ë„ì›€ë§ ì¶œë ¥
    if not args.pdf and not args.query:
        parser.print_help()
        return
    
    verbose = not args.quiet
    
    # PDF ì²˜ë¦¬
    if args.pdf:
        success = run_ingestion_pipeline(args.pdf, verbose=verbose)
        if not success:
            sys.exit(1)
        print()  # ë¹ˆ ì¤„
    
    # ì§ˆì˜ ì²˜ë¦¬
    if args.query:
        success = run_query(args.query, verbose=verbose)
        if not success:
            sys.exit(1)


if __name__ == "__main__":
    main()
